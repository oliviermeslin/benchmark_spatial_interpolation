{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqacmT1pCbnf"
      },
      "source": [
        "\n",
        "This notebook runs a `RandomizedSearchCV` to find optimal parameters for the stable models in the benchmark\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GWZ6eHhyCh_K"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "import gc\n",
        "import time\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "import xgboost\n",
        "\n",
        "# Custom wrappers/utils\n",
        "from utils.migbt import SklearnMIXGBooster\n",
        "from utils.kriging_wrapper import PyKrigeWrapper\n",
        "from utils.gam_wrapper import PyGAMWrapper\n",
        "from utils.functions import AddCoordinatesRotation, ConvertToPandas\n",
        "from utils.s3 import get_df_from_s3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcz-QnoDCnqt"
      },
      "source": [
        "---\n",
        "# Configuration\n",
        "---\n",
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wYbzv9uICLj8"
      },
      "outputs": [],
      "source": [
        "# Adjust N_ITER based on your time constraints. 10-20 is usually enough for RandomizedSearch.\n",
        "N_ITER = 15\n",
        "CV_FOLDS = 3\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "TUNABLE_MODELS = [\n",
        "    {\n",
        "        \"name\": \"random_forest\",\n",
        "        \"class\": RandomForestRegressor,\n",
        "        \"search_space\": {\n",
        "            \"ml_model__n_estimators\": [100, 250, 500],\n",
        "            \"ml_model__max_features\": [\"sqrt\", 1.0],\n",
        "            \"ml_model__min_samples_leaf\": [1, 5, 10, 20],\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"xgboost\",\n",
        "        \"class\": xgboost.XGBRegressor,\n",
        "        \"search_space\": {\n",
        "            \"ml_model__n_estimators\": [200, 500, 800],\n",
        "            \"ml_model__learning_rate\": [0.01, 0.05, 0.1],\n",
        "            \"ml_model__max_depth\": [6, 8, 12],\n",
        "            \"ml_model__subsample\": [0.7, 0.8, 1.0],\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"mixgboost\",\n",
        "        \"class\": SklearnMIXGBooster,\n",
        "        \"search_space\": {\n",
        "            \"ml_model__k\": [10, 20, 40],\n",
        "            \"ml_model__lamb\": [0.001, 0.01, 0.05, 0.1],\n",
        "            \"ml_model__n_estimators\": [100, 300],\n",
        "            \"ml_model__max_depth\": [6, 10, 14]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"kriging\",\n",
        "        \"class\": PyKrigeWrapper,\n",
        "        \"search_space\": {\n",
        "            \"ml_model__variogram_model\": [\"exponential\", \"spherical\", \"gaussian\", \"linear\"],\n",
        "            \"ml_model__nlags\": [6, 10, 20],\n",
        "            \"ml_model__weight\": [True, False],\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"gam\",\n",
        "        \"class\": PyGAMWrapper,\n",
        "        \"search_space\": {\n",
        "            \"ml_model__n_splines\": [15, 25, 40, 60],\n",
        "            \"ml_model__lam\": [0.1, 0.6, 1.5, 5.0],\n",
        "            \"ml_model__spline_order\": [2, 3],\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CPEp3V-C4DC"
      },
      "source": [
        " ## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RBQiNZZfC605"
      },
      "outputs": [],
      "source": [
        "DATASETS_TO_TUNE = [\n",
        "    {\"name\": \"S-G-Sm\", \"path\": \"s3://projet-benchmark-spatial-interpolation/data/synthetic/S-G-Sm.parquet\", \"n\": 5000},\n",
        "    {\"name\": \"S-G-Lg\", \"path\": \"s3://projet-benchmark-spatial-interpolation/data/synthetic/S-G-Lg.parquet\", \"n\": 100000},\n",
        "]\n",
        "\n",
        "# %%\n",
        "def get_data(path, n):\n",
        "    print(f\"  Fetching data from {path}...\")\n",
        "    ldf = get_df_from_s3(path)\n",
        "    # Collect and ensure column names are consistent\n",
        "    df = ldf.head(n).collect()\n",
        "    X = df.select([\"x\", \"y\"])\n",
        "    # Target is usually the last column or named 'value'/'val'\n",
        "    target_col = [c for c in df.columns if c not in [\"x\", \"y\"]][0]\n",
        "    y = df.select(pl.col(target_col)).to_numpy().ravel()\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNzwXnUqDCHs"
      },
      "source": [
        "---\n",
        "# Execution\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LSEVVzFfDWdm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING TUNING FOR: S-G-Sm\n",
            "============================================================\n",
            "  Fetching data from s3://projet-benchmark-spatial-interpolation/data/synthetic/S-G-Sm.parquet...\n",
            "  > Optimizing random_forest...\n",
            "    Done. Best R2: 0.4128\n",
            "  > Optimizing xgboost...\n",
            "    Done. Best R2: 0.3864\n",
            "  > Optimizing mixgboost...\n",
            "  [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...     Done. Best R2: 0.2702\n",
            "  > Optimizing kriging...\n",
            "    Done. Best R2: 0.9890\n",
            "  > Optimizing gam...\n",
            "    Done. Best R2: -0.1316\n",
            "\n",
            "============================================================\n",
            "STARTING TUNING FOR: S-G-Lg\n",
            "============================================================\n",
            "  Fetching data from s3://projet-benchmark-spatial-interpolation/data/synthetic/S-G-Lg.parquet...\n",
            "  > Optimizing random_forest...\n",
            "    Done. Best R2: 0.1126\n",
            "  > Optimizing xgboost...\n",
            "    Done. Best R2: 0.0576\n",
            "  > Optimizing mixgboost...\n",
            "  [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=20)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=40)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...   [MI-GBT] Compute W (k=10)...     Done. Best R2: 0.0552\n",
            "  > Optimizing kriging...\n",
            "    Done. Best R2: 0.8409\n",
            "  > Optimizing gam...\n",
            "    Done. Best R2: -0.3646\n",
            "\n",
            "##############################\n",
            "FINAL TUNED PARAMETERS JSON\n",
            "##############################\n",
            "\n",
            "{\n",
            "    \"S-G-Sm\": {\n",
            "        \"random_forest\": {\n",
            "            \"n_estimators\": 500,\n",
            "            \"min_samples_leaf\": 10,\n",
            "            \"max_features\": \"sqrt\"\n",
            "        },\n",
            "        \"xgboost\": {\n",
            "            \"subsample\": 0.7,\n",
            "            \"n_estimators\": 200,\n",
            "            \"max_depth\": 12,\n",
            "            \"learning_rate\": 0.01\n",
            "        },\n",
            "        \"mixgboost\": {\n",
            "            \"n_estimators\": 100,\n",
            "            \"max_depth\": 6,\n",
            "            \"lamb\": 0.1,\n",
            "            \"k\": 10\n",
            "        },\n",
            "        \"kriging\": {\n",
            "            \"weight\": false,\n",
            "            \"variogram_model\": \"spherical\",\n",
            "            \"nlags\": 10\n",
            "        },\n",
            "        \"gam\": {\n",
            "            \"spline_order\": 3,\n",
            "            \"n_splines\": 15,\n",
            "            \"lam\": 0.6\n",
            "        }\n",
            "    },\n",
            "    \"S-G-Lg\": {\n",
            "        \"random_forest\": {\n",
            "            \"n_estimators\": 500,\n",
            "            \"min_samples_leaf\": 20,\n",
            "            \"max_features\": \"sqrt\"\n",
            "        },\n",
            "        \"xgboost\": {\n",
            "            \"subsample\": 0.7,\n",
            "            \"n_estimators\": 200,\n",
            "            \"max_depth\": 6,\n",
            "            \"learning_rate\": 0.01\n",
            "        },\n",
            "        \"mixgboost\": {\n",
            "            \"n_estimators\": 100,\n",
            "            \"max_depth\": 6,\n",
            "            \"lamb\": 0.001,\n",
            "            \"k\": 10\n",
            "        },\n",
            "        \"kriging\": {\n",
            "            \"weight\": true,\n",
            "            \"variogram_model\": \"exponential\",\n",
            "            \"nlags\": 20\n",
            "        },\n",
            "        \"gam\": {\n",
            "            \"spline_order\": 3,\n",
            "            \"n_splines\": 15,\n",
            "            \"lam\": 5.0\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "results_to_export = {}\n",
        "\n",
        "for ds_cfg in DATASETS_TO_TUNE:\n",
        "    print(f\"\\n{'='*60}\\nSTARTING TUNING FOR: {ds_cfg['name']}\\n{'='*60}\")\n",
        "    \n",
        "    # Load base data\n",
        "    X_full, y_full = get_data(ds_cfg[\"path\"], ds_cfg[\"n\"])\n",
        "    results_to_export[ds_cfg['name']] = {}\n",
        "\n",
        "    for m_cfg in TUNABLE_MODELS:\n",
        "        print(f\"  > Optimizing {m_cfg['name']}...\")\n",
        "        \n",
        "        # SPECIAL CASE: Limit Kriging to avoid O(N^3) crashes and singular matrices\n",
        "        if m_cfg['name'] == 'kriging':\n",
        "            k_limit = 2500 \n",
        "            # 1. Selection using standard Polars indexing\n",
        "            idx = np.random.choice(len(X_full), min(len(X_full), k_limit), replace=False)\n",
        "            X_tune = X_full[idx]  # Universal Polars indexing\n",
        "            y_tune = y_full[idx]  # y_full is already a numpy array from get_data\n",
        "            \n",
        "            # 2. Add jitter using Polars expressions to prevent singular matrices\n",
        "            X_tune = X_tune.with_columns([\n",
        "                (pl.col(\"x\") + np.random.normal(0, 1e-9, len(X_tune))),\n",
        "                (pl.col(\"y\") + np.random.normal(0, 1e-9, len(X_tune)))\n",
        "            ])\n",
        "            \n",
        "            current_n_jobs = 1 # Sequential to prevent RAM explosion\n",
        "        else:\n",
        "            X_tune, y_tune = X_full, y_full\n",
        "            current_n_jobs = -1 # Parallelize other models\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            (\"coord_rotation\", AddCoordinatesRotation(coordinates_names=(\"x\", \"y\"), number_axis=1)),\n",
        "            (\"pandas_converter\", ConvertToPandas()),\n",
        "            (\"ml_model\", m_cfg[\"class\"]())\n",
        "        ])\n",
        "\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=pipeline,\n",
        "            param_distributions=m_cfg[\"search_space\"],\n",
        "            n_iter=N_ITER,\n",
        "            cv=CV_FOLDS,\n",
        "            scoring='r2',\n",
        "            n_jobs=current_n_jobs,\n",
        "            random_state=RANDOM_STATE\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            search.fit(X_tune, y_tune)\n",
        "            clean_params = {k.split(\"__\")[1]: v for k, v in search.best_params_.items()}\n",
        "            results_to_export[ds_cfg['name']][m_cfg['name']] = clean_params\n",
        "            print(f\"    Done. Best R2: {search.best_score_:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"    [SKIP] {m_cfg['name']} failed: {e}\")\n",
        "\n",
        "    del X_full, y_full\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"#\" * 30)\n",
        "print(\"FINAL TUNED PARAMETERS JSON\")\n",
        "print(\"#\" * 30 + \"\\n\")\n",
        "print(json.dumps(results_to_export, indent=4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
